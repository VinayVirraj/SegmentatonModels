{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xries4NzrWFm",
    "outputId": "751c5a16-cf29-4ae7-ee6d-d54a05fe1bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Y3kMMOEKrdLc"
   },
   "outputs": [],
   "source": [
    "# !unzip /content/drive/MyDrive/capstone_models/final_data.zip -d /content/drive/MyDrive/capstone_models/final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fg5rpNharwhO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gMvSgper1AV_"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "93i-_WcGjkis",
    "outputId": "3b0e3806-d6ec-48d0-caa8-bf0abc90d62a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YSKkMD8oslL8"
   },
   "outputs": [],
   "source": [
    "def load_images(directory_path, resize_shape=(128, 128)):\n",
    "    image_list = []\n",
    "    files = sorted(os.listdir(directory_path))\n",
    "\n",
    "    for file in files:\n",
    "        img_path = os.path.join(directory_path, file)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, resize_shape)\n",
    "        image_list.append(img)\n",
    "\n",
    "    return np.array(image_list)\n",
    "\n",
    "# Loading original images and masks\n",
    "root = '/content/drive/MyDrive/capstone_models/final_data'\n",
    "image_folder = root + '/images'\n",
    "mask_folder = root + '/mask'\n",
    "\n",
    "images = load_images(image_folder)\n",
    "masks = load_images(mask_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lp-wDGPXtOZi",
    "outputId": "668c4889-1261-423e-8b07-b69bc7c0e8c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4vXXCpHZt8Sb",
    "outputId": "5be7aef1-8a7c-47e0-f5db-d5ca4347627c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "WyOv2OKDuoY_"
   },
   "outputs": [],
   "source": [
    "def convert_masks_to_binary(masks):\n",
    "    binary_masks = []\n",
    "    for mask in masks:\n",
    "        gray_mask = cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY)\n",
    "        _, binary_mask = cv2.threshold(gray_mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        binary_masks.append(binary_mask / 255.0)\n",
    "    return np.array(binary_masks)\n",
    "\n",
    "masks = convert_masks_to_binary(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pki6JB0SzVGJ"
   },
   "outputs": [],
   "source": [
    "class CottonDataset(Dataset):\n",
    "  def __init__(self, images, masks, transform=None):\n",
    "    self.images = images\n",
    "    self.masks = masks\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.images)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image = self.images[idx]\n",
    "    mask = self.masks[idx]\n",
    "\n",
    "    image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "    mask = torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PhFeFIlY2Eob"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lqjurkYH2ltI"
   },
   "outputs": [],
   "source": [
    "dataset = CottonDataset(images, masks, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uyMYd-q0W28V"
   },
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(dataset))  # 70% for training\n",
    "val_size = int(0.15 * len(dataset))   # 15% for validation\n",
    "test_size = len(dataset) - train_size - val_size  # Remaining 15% for testing\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kmhvtTqJXMoQ"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SqJGjasLu41B"
   },
   "outputs": [],
   "source": [
    "class DoubleConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class DownConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConvBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class UpConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=3, stride=2, output_padding=1, padding=1)\n",
    "        self.conv = DoubleConvBlock(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "\n",
    "        _, _, current_height, current_width = x2.shape\n",
    "        _, _, target_height, target_width = x1.shape\n",
    "        crop_height = (current_height - target_height) // 2\n",
    "        crop_width = (current_width - target_width) // 2\n",
    "        cropped_output = x2[:, :,crop_height:crop_height + target_height, crop_width:crop_width + target_width]\n",
    "\n",
    "        x = torch.cat([cropped_output, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "  def __init__(self, in_channels, out_channels):\n",
    "    super(OutConv, self).__init__()\n",
    "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BEAqpfF28f7"
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.enc1 = (DoubleConvBlock(in_channels, 64))\n",
    "        self.enc2 = (DownConvBlock(64, 128))\n",
    "        self.enc3 = (DownConvBlock(128, 256))\n",
    "        self.enc4 = (DownConvBlock(256, 512))\n",
    "        self.bottleneck = (DownConvBlock(512, 1024))\n",
    "        self.dec4 = (UpConvBlock(1024, 512))\n",
    "        self.dec3 = (UpConvBlock(512, 256))\n",
    "        self.dec2 = (UpConvBlock(256, 128))\n",
    "        self.dec1 = (UpConvBlock(128, 64))\n",
    "        self.outc = (OutConv(64, out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(x1)\n",
    "        x3 = self.enc3(x2)\n",
    "        x4 = self.enc4(x3)\n",
    "        x5 = self.bottleneck(x4)\n",
    "        x = self.dec4(x5,x4)\n",
    "        x = self.dec3(x,x3)\n",
    "        x = self.dec2(x,x2)\n",
    "        x = self.dec1(x,x1)\n",
    "        out = self.outc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ExCe7mRvSs4Y"
   },
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1e-7):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        y_pred = y_pred.view(-1)\n",
    "        y_true = y_true.view(-1)\n",
    "\n",
    "        intersection = (y_pred * y_true).sum()\n",
    "        dice_coeff = (2. * intersection + self.smooth) / (y_pred.sum() + y_true.sum() + self.smooth)\n",
    "        dice_loss = 1 - dice_coeff\n",
    "\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TbRskik6Adbg"
   },
   "outputs": [],
   "source": [
    "# unet_model = UNet(in_channels=3, out_channels=1).to(device)\n",
    "# images, masks = next(iter(dataloader))\n",
    "# output = unet_model(images.to(device))\n",
    "# print(\"Output shape from U-Net:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pf1fN5dGzioR"
   },
   "outputs": [],
   "source": [
    "model = UNet(in_channels=3, out_channels=1).to(device)\n",
    "criterion = DiceLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqWUKNFxTOgu",
    "outputId": "953491c1-0177-4311-991c-1c9a974302be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [41:53<00:00, 61.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1],  Train Loss: 0.9158, Validation Loss: 0.8810\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  train_running_loss = 0\n",
    "\n",
    "  for images, masks in tqdm(train_loader):\n",
    "    images = images.to(device)\n",
    "    masks = masks.to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    output = model(images)\n",
    "\n",
    "    loss = criterion(output, masks)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    train_running_loss += loss.item()\n",
    "\n",
    "  epoch_loss = train_running_loss / len(train_loader)\n",
    "\n",
    "  model.eval()\n",
    "  val_loss = 0\n",
    "  with torch.no_grad():\n",
    "      for val_images, val_masks in val_loader:\n",
    "          val_images = val_images.to(device)\n",
    "          val_masks = val_masks.to(device)\n",
    "\n",
    "          val_output = model(val_images)\n",
    "          val_loss += criterion(val_output, val_masks).item()\n",
    "\n",
    "  val_loss = val_loss / len(val_loader)\n",
    "  print(f\"Epoch [{epoch + 1}/{num_epochs}],  Train Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "w1ST7TOfUAHz"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_predictions = []\n",
    "test_ground_truths = []\n",
    "with torch.no_grad():\n",
    "  for test_images, test_masks in test_loader:\n",
    "    test_images = test_images.to(device)\n",
    "\n",
    "    test_pred = model(test_images)\n",
    "\n",
    "    test_predictions.append(test_pred.cpu().numpy())\n",
    "    test_ground_truths.append(test_masks.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "AyEfx-CjZziG",
    "outputId": "2c71af04-4943-468c-b42a-7c77a0b96a18"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-59390c872669>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RhkGrV_saA5e"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
